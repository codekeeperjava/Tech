## 为什么使用消息队列（消息队列的优点）

1. 削峰填谷
2. 异步
3. 解耦

削峰填谷 : 通常 80% 的请求发生在 20% 的时间内，因此对于大部分时间，我们的系统压力不大，但对于流量峰值时，我们系统又得承受非常大的压力。可以先将请求发送到消息队列，然后服务根据自己能力消费，可以均衡请求。

异步 : 比如异步发送日志，可以让系统快速放回。

解耦 : 生产者不用关心谁使用这些数据，添加消费者也不用通知生产者。

## 消息队列的缺点

1. 系统可用性降低
2. 系统复杂度提高
3. 一致性问题

系统可用性降低 : 如果消息队列出现消息丢失、消息重复和消息乱序的情况，则会引起后面系统出现问题。当 MQ 出现故障，可能导致依赖消费 MQ 的程序都无法运行的情况。

系统复杂性提高 : 本来两个系统可以直接调用，通过添加了 MQ 增加了业务处理的复杂性。

一致性问题 : 比如一个系统已经给用户成功，这时候操作 BC 都成功了，操作 D 失败了，导致数据不一致。

## 消息队列的技术选型

|            | ActiveMQ           |     RabbitMQ           |    RocketMQ               | Kafka                    |
| ---------- | ------------------ | ---------------------- | ------------------------ | ------------------------------------ |
| 单机吞吐量 | 万级别             | 万级别                 | 十万级别                 | 十万级别                             |
| 时效性     | ms                 | 微秒                   | ms                       | ms 以内                               |
| 集群扩展性 | 高，基于主从       | 高，基于主从           | 非常高，基于集群         | 非常高，基于集群                     |
| 系统稳定性 | 有较低概率丢失数据 |                        | 经过参数优化，可以 0 丢失  | 经过参数优化，可以 0 丢失              |
| 功能完备性 | MQ 功能及其完备     | 功能完备，后台监控强大 | 功能较完备，分布式扩展好 | 功能较简单，支持简单的 MQ，扩展能力强 |
| 开发语言   |                    | erlang                 | Java                     | Java                                 |
| 社区活跃度 | 不活跃             | 很活跃                 | 活跃                     | 很活跃                               |

主要优缺点比较：

- ActiveMQ 比较老，曾经霸占了国内使用 MQ 的场景，但现在社区活跃程度低，吞吐量也表现不好。
- RabbitMQ 开源版本可用功能多，后台完善，性能很好。但由于使用 erlang 开发，国内公司可能很少有人能基于源码开发。
- RoctetMQ，阿里开源，在阿里内部大量使用。性能好，易扩展，功能强大，基于 Java 开发易于维护。
- Kafka，功能简单，但吞吐量非常高，易扩展，基于 Java 开发易于维护。是大数据领域如实时计算、日志采集的规范。

选型：

- 小公司可以使用 RabbitMQ， 功能足够强大，社区活跃有保障
- 大中型公司可以选择 RocketMQ， 性能好，易扩展。基于 Java 方便维护 u。
- 实时计算、日志采集无论大小公司都可以选择 Kafka。

## 消费队列的应用场景

我们公司作为一个资讯流推荐公司，对用户的行为（点击、阅读、点赞等某篇内容）都需要收集，只用到了简单的 MQ 功能，因此 Kafka 是最好的选择。
当然，除了日志收集外，日志的使用（流计算）也很关键，我们需要根据用户的请求，流式计算用户的各种历史数据，为用户推荐合适的资讯。

MySQL 数据同步，刚开始我们使用自己搭建的 MySQL 到 Elasticsearch 数据同步，使用 canel 将 binlog 发送到 MQ 中，由程序消费写入 Elasticsearch 中，此时要求数据可靠性非常高，但吞吐量并不大，可以考虑使用 RocketMQ 。

## 引入消息队列后如何实现 HA

MQ 的高可用模式分为单机模式、主从模式和集群模式。

RabbitMQ 比较典型，它拥有单机模式和主从模式。Kafka 是集群模式。

其中单机模式不用说了，没有什么 HA 可言，挂掉直接不可用。

### RabbitMQ 普通模式

![2020082723dymSjUe203f28c.png](http://img.dotleo.cn/blog/2020082723dymSjUe203f28c.png)

该模式下，queue 存在于一个结点上，同时所有结点都存储所有结点的元数据。当消费者消费时，如果连接到了 queue 所在的结点，则可以直接获取数据；如果连接到了其他结点，则需要和 queue 所在结点进行通信，获取到数据后返回给消费者。

这种模式也没有高可用可言，可能当非 queue 的结点挂掉后还能正常提供服务，但当 queue 结点挂掉后，就无法提供服务。

### RabbitMQ 镜像模式

![2020082723HsFX3D849d3480.png](http://img.dotleo.cn/blog/2020082723HsFX3D849d3480.png)

该模式下，写入的消息会在每一个结点的 queue 中都存储一份，消费者可以在连接任一结点后进行读取。

这种模式可以实现高可用，当其中一个结点挂掉后，系统仍然能够提供服务，但该模式存在单机限制且有很大的数据冗余。

### Kafka 集群模式

![2020082723UxL3UJ6b682499.png](http://img.dotleo.cn/blog/2020082723UxL3UJ6b682499.png)

Kafka 有 Partition 的概念， 将整个 Topic 的消息存储进行分割。并且通过 Replica 实现高可用。每个 Partition 都可以设置多个 Replica ， 相同的 Partition 的副本不会存储在一个机器。当消费者消费时，也会先根据 Partition 分配相应的机器进行连接。

这种模式可以实现高可用，当一个结点挂掉后，另一个结点上依然存在该结点 Partition 的 Replica 可以继续提供服务。

## 如何保证消息不被重复消费（消息的幂等性）

//TODO Kafka 的重复消费场景需要补充

offset 还没有提交就挂掉了

1. 判断唯一属性如果存在则不执行，如果不存在再执行。
2. 往 Redis 中插入完成事务的唯一属性，每次消费后通过 Redis 去重。
3. 利用数据库等唯一约束。

## 如何保证消息不丢失

### RabbitMQ 保证数据不丢失

RabbitMQ 数据丢失的 3 个环节：

1. 生产者生产消息，但因为网络等原因，它自己以为发送出去了，但 MQ 没有接收到或者接收到存储失败的情况。
2. MQ 本身可能丢失数据。比如 MQ 在收到生产者数据时，会先存到内存中，然后定时刷盘。过程中可能出现突然挂掉导致数据丢失的情况。
3. 消费者消费到数据后，还没来得及处理完毕，服务挂掉了。但 MQ 以为消费者已经完成了操作，下次不会再发送丢失的数据导致丢失。

解决方案：

1. 可以使用同步事务的方式，如果提交给 MQ 抛出异常则回滚事务并重试；也可以采用异步 confirm 的方式，当和 MQ 通信失败或存储失败时，通过回调函数处理该消息。
2. 创建 queue 时设置为持久化，这时持久化的是元数据；另外需要对发送消息的时候将消息的 deliveryMode 设置为 2，会将消息也持久化到磁盘。
3. 消费者丢失消息一般是因为消费者打开了 autoAck 机制，消费者消费了消息后，还没有处理完就自动通知 MQ 这条数据已经消费了。可以关闭 autoAck 机制，在消费且处理完后，手动 ack。

### Kafka 保证数据不丢失

Kafka 数据丢失的 3 个环节：

1. Producer 没有确认机制，导致发送完消息后 Broker 没有存储成功，就会导致丢失。
2. Broker 本身存在丢失数据的风险，比如 Broker 将数据存到了 Leader Partition 后，还没有同步到 Follower Partition，就挂掉了，然后 Follower Partition 切换为 Leader Partition，此时就会丢失这部分没有同步的数据。
3. 消费者消费到数据后，还没有来得及处理完毕，服务器挂掉了。但 Broker 以为消费者已经完成了操作，下次不会再发送丢失的数据导致丢失。（和 RabbitMQ 基本一致）

解决方案：

1. ack 的取值有 0、 1、 -1，当等于 0 时，Producer 只管发送数据，因此只要不设置为 0， 则至少 Broker 会将数据写到 Leader Partition 后才会返回响应，如果要完全不丢失，则需要设置为 -1， 此时消息同步到所有的 Partition 后才会返回响应。
2. 同时满足一下 4 个条件：
   - 启动时，replication.factor 必须大于 1。
   - 设置最小同步副本数必须大于 1，要求至少一个 Partition 在运行过程中至少有 1 个 Follower。
   - 在 Producer 端设置 ack = -1， 代表当 Broker 将数据同步到所有 Follower 之后才能给 Producer 响应。
   - Producer 发送数据到 Broker 失败后，需要配置相应的逻辑确保有记录。
3. 消费者不要设置 offset 自动提交，在事务结束后手动提交。

## 如何保证消息顺序

### Kafka 如何保证消息顺序

Kafka 本身通过 Key hash 的方式分配 Partition 的机制，可以保证同一 Key 的消息发送到同一个 Partition 中，也由于一个 Partition 只能被一个 Consumer 消费，因此在 Consumer 消费完消息后，单线程处理消息时就已经能满足消息的顺序性。

![20200828167dfGqJ77fe36d1.png](http://img.dotleo.cn/blog/20200828167dfGqJ77fe36d1.png)

如下图所示，但我们往往不满足于 Consumer 消费到消息以后单线程处理消息，当简单的使用多线程处理消费到的消息时，就会因为每个线程的执行效率等问题导致消息顺序得不到保障：

![2020082816fhp2Irb14806b3.png](http://img.dotleo.cn/blog/2020082816fhp2Irb14806b3.png)

**这是 Kafka 出现消息顺序不一致的唯一情况**，在这种情况下，我们可以模仿 Kafka 通过 Key hash 的方式分配 Partition 的机制，增加内存队列，通过 hash 的方式将相同的 key 发送到同一个内存队列，让线程通过内存队列获取消息，这样就可以保证相同 Key 的顺序性。

![20200828166EIN5u08d680cc.png](http://img.dotleo.cn/blog/20200828166EIN5u08d680cc.png)

## 消息堆积

### 延时过高

延时过高是指因为某些原因导致消息堆积，消费者消费的内容落后于生产者生产消息太多。一般原因是因为消费者程序出现问题阻塞导致。此时第一步是修复消费者程序的问题，除此之外，受限于消费者本身的消费速度并没有增加，因此需要通过额外的措施来消费堆积的消息。

假设之前有一个 Topic 拥有 3 个 Partition，现在我们创建一个有 10 个 Partition 的 Topic，并用程序直接将旧 Topic 中的消息写入到新 Topic 中，然后启用 10 个 Consumer 进行处理。

![2020083115uL8AkYd5b545bd.png](http://img.dotleo.cn/blog/2020083115uL8AkYd5b545bd.png)

### 过期失效

过期失效是指，消息队列设置了过期时间，当消息堆积超过了过期时间，还没有消费导致已经被消息中间件删除的情况 。如果出现这种情况，就要求设计上，对消息的内容进行备份，比如日志等。

通常只能通过读日志、或者读库等方式重建消息。

### MQ 磁盘存满

磁盘存满指消息堆积无法消费删除时，大量消息占用了过多磁盘空间导致磁盘容量不够用的情况。一般是因为消息消费延时过高，我们同样可以在其他服务器上创建 Topic，然后通过程序将消息快速的发送到新的 Topic 存储，达到快速解决消息堆积从而缓解磁盘压力。

## 试设计一个消息队列

设计一个消费队列的问题，其实考察的是对消息中间件的一个整体架构的把握情况。

我暂时可以认为有以下几个方面展开：

1. 基本功能的实现
   - 生产者的生产流程的实现
   - 生产者发送时消息时协议的定义
   - 生产者网络通信的实现
   - 服务端和生产者的网络通信实现
   - 服务端消息处理的实现
   - 网络端和消费者的网络通信实现
2. 高并发和高性能
   - 参考 Kafka Partition 的实现
   - NIO 方式的网络通信
   - 参考 Kafka 落盘的实现
3. 高可用
   - 参考 Kafka Partition 和 Replica 的实现
   - 消息重复问题的解决
   - 消息丢失问题的解决
   - 消息顺序问题的解决

## Kafka 相关面试题

1. 复制的底层原理
2. leader 的选举算法
3. 增加 Partition 以后的 rebalance 算法
4. 如何优化 Kafka 的吞吐量

## 参考文章

1. [kafka 系列八、kafka 消息重复和丢失的场景及解决方案分析 - 小人物的奋斗 - 博客园](https://www.cnblogs.com/wangzhuxing/p/10124308.html#_label0)
